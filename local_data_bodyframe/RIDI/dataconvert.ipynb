{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Raw IMU Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['zhicheng_body1', 'xiaojing_body2', 'hang_body_test1', 'ruixuan_body1', 'hang_body_backward2', 'hang_body_slow1', 'ma_body2', 'hang_body_normal1', 'hang_body_backward1', 'zhicheng_body2', 'dan_body2', 'ma_body1', 'yajie_body2', 'hang_body_side1', 'hang_body_fast1', 'dan_body3', 'hang_body_stop1', 'xiaojing_body1', 'tang_body1', 'huayi_body_test1', 'ruixuan_body2', 'hao_body1', 'tang_body2', 'hang_body_backward4', 'hang_body_backward3', 'dan_body1', 'yajie_body1', 'hao_body2']\n",
      "Processing folder:  zhicheng_body1\n",
      "Processing folder:  xiaojing_body2\n",
      "Processing folder:  hang_body_test1\n",
      "Processing folder:  ruixuan_body1\n",
      "Processing folder:  hang_body_backward2\n",
      "Processing folder:  hang_body_slow1\n",
      "Processing folder:  ma_body2\n",
      "Processing folder:  hang_body_normal1\n",
      "Processing folder:  hang_body_backward1\n",
      "Processing folder:  zhicheng_body2\n",
      "Processing folder:  dan_body2\n",
      "Processing folder:  ma_body1\n",
      "Processing folder:  yajie_body2\n",
      "Processing folder:  hang_body_side1\n",
      "Processing folder:  hang_body_fast1\n",
      "Processing folder:  dan_body3\n",
      "Processing folder:  hang_body_stop1\n",
      "Processing folder:  xiaojing_body1\n",
      "Processing folder:  tang_body1\n",
      "Processing folder:  huayi_body_test1\n",
      "Processing folder:  ruixuan_body2\n",
      "Processing folder:  hao_body1\n",
      "Processing folder:  tang_body2\n",
      "Processing folder:  hang_body_backward4\n",
      "Processing folder:  hang_body_backward3\n",
      "Processing folder:  dan_body1\n",
      "Processing folder:  yajie_body1\n",
      "Processing folder:  hao_body2\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "## functions to use\n",
    "def from_quaternion(quat, ordering='wxyz'):\n",
    "        \"\"\"Form a rotation matrix from a unit length quaternion.\n",
    "        Valid orderings are 'xyzw' and 'wxyz'.\n",
    "        \"\"\"\n",
    "        if ordering == 'xyzw':\n",
    "            qx = quat[:, 0]\n",
    "            qy = quat[:, 1]\n",
    "            qz = quat[:, 2]\n",
    "            qw = quat[:, 3]\n",
    "        elif ordering == 'wxyz':\n",
    "            qw = quat[:, 0]\n",
    "            qx = quat[:, 1]\n",
    "            qy = quat[:, 2]\n",
    "            qz = quat[:, 3]\n",
    "\n",
    "        # Form the matrix\n",
    "        mat = quat.new_empty(quat.shape[0], 3, 3)\n",
    "\n",
    "        qx2 = qx * qx\n",
    "        qy2 = qy * qy\n",
    "        qz2 = qz * qz\n",
    "\n",
    "        mat[:, 0, 0] = 1. - 2. * (qy2 + qz2)\n",
    "        mat[:, 0, 1] = 2. * (qx * qy - qw * qz)\n",
    "        mat[:, 0, 2] = 2. * (qw * qy + qx * qz)\n",
    "\n",
    "        mat[:, 1, 0] = 2. * (qw * qz + qx * qy)\n",
    "        mat[:, 1, 1] = 1. - 2. * (qx2 + qz2)\n",
    "        mat[:, 1, 2] = 2. * (qy * qz - qw * qx)\n",
    "\n",
    "        mat[:, 2, 0] = 2. * (qx * qz - qw * qy)\n",
    "        mat[:, 2, 1] = 2. * (qw * qx + qy * qz)\n",
    "        mat[:, 2, 2] = 1. - 2. * (qx2 + qy2)\n",
    "        return mat\n",
    "\n",
    "def slerp(q0, q1, tau, DOT_THRESHOLD = 0.9995):\n",
    "    \"\"\"Spherical linear interpolation.\"\"\"\n",
    "\n",
    "    dot = (q0*q1).sum(dim=1)\n",
    "    q1[dot < 0] = -q1[dot < 0]\n",
    "    dot[dot < 0] = -dot[dot < 0]\n",
    "\n",
    "    q = torch.zeros_like(q0)\n",
    "    tmp = q0 + tau.unsqueeze(1) * (q1 - q0)\n",
    "    tmp = tmp[dot > DOT_THRESHOLD]\n",
    "    q[dot > DOT_THRESHOLD] = tmp / tmp.norm(dim=1, keepdim=True)\n",
    "\n",
    "    theta_0 = dot.acos()\n",
    "    sin_theta_0 = theta_0.sin()\n",
    "    theta = theta_0 * tau\n",
    "    sin_theta = theta.sin()\n",
    "    s0 = (theta.cos() - dot * sin_theta / sin_theta_0).unsqueeze(1)\n",
    "    s1 = (sin_theta / sin_theta_0).unsqueeze(1)\n",
    "    q[dot < DOT_THRESHOLD] = ((s0 * q0) + (s1 * q1))[dot < DOT_THRESHOLD]\n",
    "    return q / q.norm(dim=1, keepdim=True)\n",
    "\n",
    "def qinterp(qs, t, t_int):\n",
    "    idxs = np.searchsorted(t, t_int)\n",
    "    idxs0 = idxs-1\n",
    "    idxs0[idxs0 < 0] = 0\n",
    "    idxs1 = idxs\n",
    "    idxs1[idxs1 == t.shape[0]] = t.shape[0] - 1\n",
    "    q0 = qs[idxs0]\n",
    "    q1 = qs[idxs1]\n",
    "    tau = torch.zeros_like(t_int)\n",
    "    dt = (t[idxs1]-t[idxs0])[idxs0 != idxs1]\n",
    "    tau[idxs0 != idxs1] = (t_int-t[idxs0])[idxs0 != idxs1]/dt\n",
    "    return slerp(q0, q1, tau)\n",
    "\n",
    "def qnorm(q):\n",
    "    \"Quaternion normalization\"\n",
    "    return q / q.norm(dim=1, keepdim=True)\n",
    "\n",
    "\n",
    "def interpolate(x, t, t_int):\n",
    "    \"\"\"\n",
    "    Interpolate ground truth at the sensor timestamps\n",
    "    \"\"\"\n",
    "\n",
    "    # vector interpolation\n",
    "    x_int = np.zeros((t_int.shape[0], x.shape[1]))\n",
    "    for i in range(x.shape[1]):\n",
    "        if i in [4, 5, 6, 7]:\n",
    "            continue\n",
    "        x_int[:, i] = np.interp(t_int, t, x[:, i])\n",
    "    # quaternion interpolation\n",
    "    t_int = torch.Tensor(t_int - t[0])\n",
    "    t = torch.Tensor(t - t[0])\n",
    "    qs = qnorm(torch.Tensor(x[:, 4:8]))\n",
    "    x_int[:, 4:8] = qinterp(qs, t, t_int).numpy()\n",
    "    return x_int\n",
    "\n",
    "# Get the current directory\n",
    "current_dir = os.getcwd()\n",
    "\n",
    "# List all directories in the current directory\n",
    "folders = [f for f in os.listdir(current_dir) if os.path.isdir(os.path.join(current_dir, f))]\n",
    "\n",
    "print(folders)\n",
    "\n",
    "for dir_name in folders:\n",
    "    print(\"Processing folder: \", dir_name)\n",
    "    imu_path = os.path.join(current_dir, dir_name, \"mav0/imu0/data.csv\")\n",
    "    gt_path = os.path.join(current_dir, dir_name, \"mav0/state_groundtruth_estimate0/data.csv\")\n",
    "\n",
    "    imu = np.genfromtxt(imu_path, delimiter=\",\", skip_header=1)\n",
    "    gt = np.genfromtxt(gt_path, delimiter=\",\", skip_header=1)\n",
    "\n",
    "    # time synchronization between IMU and ground truth\n",
    "    t0 = np.max([gt[0, 0], imu[0, 0]])\n",
    "    t_end = np.min([gt[-1, 0], imu[-1, 0]])\n",
    "\n",
    "    # start index\n",
    "    idx0_imu = np.searchsorted(imu[:, 0], t0)\n",
    "    idx0_gt = np.searchsorted(gt[:, 0], t0)\n",
    "\n",
    "    # end index\n",
    "    idx_end_imu = np.searchsorted(imu[:, 0], t_end, 'right')\n",
    "    idx_end_gt = np.searchsorted(gt[:, 0], t_end, 'right')\n",
    "\n",
    "    # subsample\n",
    "    imu = imu[idx0_imu: idx_end_imu]\n",
    "    gt = gt[idx0_gt: idx_end_gt]\n",
    "    ts_imu = imu[:, 0]\n",
    "\n",
    "    # interpolate\n",
    "    gt = interpolate(gt, gt[:, 0], ts_imu) # quaternion order: w, x, y, z\n",
    "\n",
    "    ts_data = ts_imu / 1e3 # convert to microseconds\n",
    "\n",
    "    assert (ts_data[-1] - ts_data[0]) /1e6 > 0 and (ts_data[-1] - ts_data[0])/1e6 < 380.0, \"The duration of the dataset is: \" + str((ts_data[-1] - ts_data[0])/1e6)\n",
    "    gyr_data = imu[:, 1:4]\n",
    "    acc_data = imu[:, 4:7]\n",
    "    q_data = gt[:, 4:8] # order: w, x, y, z\n",
    "    R_rot = from_quaternion(torch.from_numpy(q_data), ordering='wxyz')\n",
    "    # convert to order: x, y, z, w\n",
    "    q_data = q_data[:, [1, 2, 3, 0]]\n",
    "    pos_data = gt[:, 1:4]\n",
    "    vel_data = gt[:, 8:11]\n",
    "    # convert vel_world to vel_body\n",
    "    # R_rot = from_quaternion(torch.from_numpy(q_data), ordering='xyzw')\n",
    "    vel_data = (R_rot.transpose(-1,-2) @ torch.from_numpy(vel_data).unsqueeze(-1)).squeeze(-1).numpy()\n",
    "    # print(\"vel_data[0]\", vel_data[0])\n",
    "\n",
    "    # Write npy files\n",
    "    data_save = np.hstack((ts_data.reshape(-1, 1), gyr_data, acc_data, q_data, pos_data, vel_data))\n",
    "    np.save(dir_name + '/imu0_resampled.npy', data_save)\n",
    "\n",
    "    # Write JSON file\n",
    "    num_rows = imu.shape[0]\n",
    "    t_start_us = imu[0, 0]\n",
    "    t_end_us = imu[-1, 0]\n",
    "    json_data = {\n",
    "    \"columns_name(width)\": [\n",
    "        \"ts_us(1)\",\n",
    "        \"gyr_compensated_rotated_in_World(3)\",\n",
    "        \"acc_compensated_rotated_in_World(3)\",\n",
    "        \"qxyzw_World_Device(4)\",\n",
    "        \"pos_World_Device(3)\",\n",
    "        \"vel_Body(3)\"\n",
    "    ],\n",
    "    \"num_rows\": num_rows,\n",
    "    \"approximate_frequency_hz\": 200.0,\n",
    "    \"t_start_us\": t_start_us,\n",
    "    \"t_end_us\": t_end_us\n",
    "    }    \n",
    "    with open(dir_name+ '/imu0_resampled_description.json', 'w') as json_file:\n",
    "        json.dump(json_data, json_file, indent=4)  # 'indent=4' makes the JSON file readable (pretty-printed)\n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select Train, Val and Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_dir) /home/sangli/Ben/code/imu-equivariant-learning/local_data_bodyframe/RIDI\n",
      "total number of sequences:  28\n",
      "number of training sequences:  24\n",
      "number of validation sequences:  2\n",
      "number of test sequences:  2\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import math\n",
    "\n",
    "current_dir = os.getcwd()\n",
    "print(\"current_dir)\", current_dir)\n",
    "seq = [f for f in os.listdir(current_dir) if os.path.isdir(os.path.join(current_dir, f))]\n",
    "random.shuffle(seq)\n",
    "\n",
    "num_val = math.floor(len(seq) // 10)\n",
    "num_test = math.floor(len(seq) // 10)\n",
    "index_end_train = len(seq) - num_val - num_test\n",
    "print(\"total number of sequences: \", len(seq))\n",
    "print(\"number of training sequences: \", index_end_train)\n",
    "print(\"number of validation sequences: \", num_val)\n",
    "print(\"number of test sequences: \", num_test)\n",
    "\n",
    "all_ids_txt_path = os.path.join(current_dir, 'all_ids.txt')\n",
    "train_list_txt_path = os.path.join(current_dir, 'train_list.txt')\n",
    "val_list_txt_path = os.path.join(current_dir, 'val_list.txt')\n",
    "test_list_txt_path = os.path.join(current_dir, 'test_list.txt')\n",
    "with open(all_ids_txt_path, 'w') as f:\n",
    "    pass\n",
    "with open(train_list_txt_path, 'w') as f:\n",
    "    pass\n",
    "with open(val_list_txt_path, 'w') as f:\n",
    "    pass\n",
    "with open(test_list_txt_path, 'w') as f:\n",
    "    pass\n",
    "for i, seq in enumerate(seq):\n",
    "    with open(all_ids_txt_path, 'a') as f:\n",
    "        f.write(seq + '\\n')\n",
    "    if i < index_end_train:\n",
    "        with open(os.path.join(current_dir, 'train_list.txt'), 'a') as f:\n",
    "            f.write(seq + '\\n')\n",
    "    elif i < index_end_train + num_val:\n",
    "        with open(os.path.join(current_dir, 'val_list.txt'), 'a') as f:\n",
    "            f.write(seq + '\\n')\n",
    "    else:\n",
    "        with open(os.path.join(current_dir, 'test_list.txt'), 'a') as f:\n",
    "            f.write(seq + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_dir) /home/sangli/Ben/code/imu-equivariant-learning/local_data_bodyframe/RIDI\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "ridi_data_path = '/home/sangli/Downloads/DATASET/ridi-robust-imu-double-integration/versions/1/data_publish_v2/dan_bag1'\n",
    "path_tmp = os.path.join(ridi_data_path, 'processed/')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
